{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21144156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import tangos as db\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "import random\n",
    "\n",
    "import foggie.utils.foggie_load as fog\n",
    "import yt\n",
    "from yt.units.yt_array import YTQuantity, YTArray\n",
    "from yt.data_objects.particle_filters import add_particle_filter\n",
    "\n",
    "import glob\n",
    "from tangos.examples.misc import timestep_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64989f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Simulation(\"Tempest.9f11c.all.DD\")>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.all_simulations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9c64c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = db.get_simulation('Tempest.9f11c.all.DD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55ec788b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Halo 'Tempest.9f11c.all.DD/DD2427/DD2427/halo_51' | NDM=182 Nstar=0 Ngas=0>]\n"
     ]
    }
   ],
   "source": [
    "all_sats = sim[-1][1].calculate('Satellites()')\n",
    "\n",
    "sats = np.array([], dtype='object')\n",
    "#starry_idx = np.array([51, 109], dtype='object')\n",
    "starry_idx = np.array([51], dtype='object')\n",
    "\n",
    "for i in range(np.size(all_sats)):\n",
    "    if all_sats[i].halo_number in starry_idx:\n",
    "        sats = np.append(sats, all_sats[i]) # this ensures we're only checking for the verified starry halos\n",
    "        \n",
    "print(sats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ab36b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.75931383 13.75655364 13.75117425 ...  0.95896446  0.95358506\n",
      "  0.9482052 ]\n",
      "Success!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "First, we find all the properties of the progenitors \n",
    "for the star-forming surviving satellites.\n",
    "\"\"\"\n",
    "\n",
    "all_sat_cen = []\n",
    "all_sat_mvir = []\n",
    "all_sat_rvir = []\n",
    "all_sat_t = []\n",
    "\n",
    "for sat_idx in starry_idx:\n",
    "    if isinstance(sim[-1][sat_idx], type(None)) is False:\n",
    "        mvir, cen, rvir, t = sim[-1][sat_idx].calculate_for_progenitors('Mvir', 'Center', 'Rvir', 't()')\n",
    "\n",
    "        all_sat_cen.append(cen) # this compiles an array of all the progenitors' centers\n",
    "        all_sat_mvir.append(mvir) # this compiles an array of all the progenitors' virial masses\n",
    "        all_sat_rvir.append(rvir) # this compiles an array of all the progenitors' virial radii\n",
    "        all_sat_t.append(t)\n",
    "        print(t)\n",
    "\n",
    "all_sat_cen = np.array(all_sat_cen[0], dtype='object')\n",
    "all_sat_mvir = np.array(all_sat_mvir[0], dtype='object')\n",
    "all_sat_rvir = np.array(all_sat_rvir[0], dtype='object')\n",
    "all_sat_t = np.array(all_sat_t[0], dtype='object')\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b744b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tslist = glob.glob('/Volumes/TempestTimeSteps/DD????/DD????') \n",
    "tslist.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c5d0937",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_time_idx = np.array([], dtype='object')\n",
    "\n",
    "for snap_name in tslist:\n",
    "    snapend = snap_name[-6:]\n",
    "    time_idx = timestep_index(sim, snapend)\n",
    "    all_time_idx = np.append(all_time_idx, time_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ac9b8d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 130 timesteps available in the star hard drive.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, we have to ensure that all the progenitors line up with the available \n",
    "timesteps in the star hard drive. To do that, we first have to convert \n",
    "all the time indices from the star hard drive to actual time in Gyr.\n",
    "\"\"\"\n",
    "\n",
    "available_timesteps = np.zeros(np.size(all_time_idx))\n",
    "i = 0\n",
    "while i < np.size(all_time_idx):\n",
    "    available_timesteps[i] = sim[all_time_idx[i]].time_gyr\n",
    "    i += 1\n",
    "    \n",
    "print('There are', np.size(available_timesteps), 'timesteps available in the star hard drive.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c66e2776",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nMoved step loading to the loop where it's first needed\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, run through ALL the files with star data in the hard drive. This should take a while.\n",
    "\"\"\"\n",
    "\n",
    "halo = 'Tempest'\n",
    "hnum = '008508'\n",
    "\n",
    "halo_c_v_name = '/Users/bnguyen/FOGGIE/foggie/halo_infos/'+hnum+'/nref11c_nref9f/halo_c_v'\n",
    "trackname = '/Users/bnguyen/FOGGIE/foggie/halo_tracks/'+hnum+'/nref11n_selfshield_15/halo_track_200kpc_nref9'\n",
    "masses_dir = '/Users/bnguyen/FOGGIE/foggie/halo_infos/'+hnum+'/nref11c_nref9f/'\n",
    "\n",
    "def StarParts(pfilter, data):\n",
    "    return data[(\"all\", \"particle_type\")] == 2 # only grab star particles\n",
    "\n",
    "add_particle_filter(\"stars\", function=StarParts, filtered_type='all', requires=[\"particle_type\"])\n",
    "\n",
    "\n",
    "'''\n",
    "Moved step loading to the loop where it's first needed\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f5cb951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "all_centers = []\n",
    "all_rvirs = []\n",
    "all_available_snaps = []\n",
    "\n",
    "#for halo in range(np.size(starry_idx)):\n",
    "\n",
    "each_halo_available_centers = []\n",
    "each_halo_available_rvirs = []\n",
    "each_halo_available_snaps = []\n",
    "    \n",
    "# Now, we compare the times in the snapshots to the available timesteps \n",
    "# in order to see how many snapshots are available in the star hard drive.\n",
    "\n",
    "for time in available_timesteps:\n",
    "    center = all_sat_cen[all_sat_t == time]\n",
    "    rvir = all_sat_rvir[all_sat_t == time]\n",
    "        \n",
    "    if np.size(center) != 0 and np.size(rvir) != 0:\n",
    "        center = YTArray(center[0] * 1000, 'kpc')\n",
    "        rvir = YTQuantity(rvir[0], 'kpc')\n",
    "            \n",
    "        each_halo_available_centers.append(center)\n",
    "        each_halo_available_rvirs.append(rvir)\n",
    "        each_halo_available_snaps.append(np.array(tslist)[available_timesteps == time][0])\n",
    "            \n",
    "each_halo_available_centers = np.array(each_halo_available_centers, dtype='object')\n",
    "each_halo_available_rvirs = np.array(each_halo_available_rvirs, dtype='object')\n",
    "each_halo_available_snaps = np.array(each_halo_available_snaps, dtype='object')\n",
    "        \n",
    "all_centers.append(each_halo_available_centers)\n",
    "all_rvirs.append(each_halo_available_rvirs)\n",
    "all_available_snaps.append(each_halo_available_snaps)\n",
    "    \n",
    "all_centers = np.array(all_centers[0], dtype='object')\n",
    "all_rvirs = np.array(all_rvirs[0], dtype='object')\n",
    "all_available_snaps = np.array(all_available_snaps[0], dtype='object')\n",
    "\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fd852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "yt : [INFO     ] 2022-07-31 11:59:17,547 Parameters: current_time              = 44.816527818285\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,549 Parameters: domain_dimensions         = [256 256 256]\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,553 Parameters: domain_left_edge          = [0. 0. 0.]\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,556 Parameters: domain_right_edge         = [1. 1. 1.]\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,556 Parameters: cosmological_simulation   = 1\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,557 Parameters: current_redshift          = 5.9180766004715\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,558 Parameters: omega_lambda              = 0.715\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,559 Parameters: omega_matter              = 0.285\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,559 Parameters: omega_radiation           = 0.0\n",
      "yt : [INFO     ] 2022-07-31 11:59:17,560 Parameters: hubble_constant           = 0.695\n",
      "Parsing Hierarchy : 100%|█████████████████| 2486/2486 [00:00<00:00, 6966.83it/s]\n",
      "yt : [INFO     ] 2022-07-31 11:59:18,039 Gathering a field list (this may take a moment.)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now, we go through each of the satellites and find the location & mass of the stars \n",
    "at each timestep, then save that into .txt files to analyze later. This is because \n",
    "we tried NumPy arrays and lists before, but that didn't end up working out.\n",
    "\"\"\"\n",
    "\n",
    "bin_size = YTQuantity(0.25, 'kpc') # 250 pc is the resolution of the simulation\n",
    "\n",
    "all_radius_arrays = []\n",
    "starry_spheres = []\n",
    "\n",
    "# each_halo_radius_arrays = []    \n",
    "# each_halo_spheres = []\n",
    "starry_steps = []\n",
    "\n",
    "# this goes through the halo at each timestep to find its Rvir and center position\n",
    "for idx in range(np.size(all_rvirs)):\n",
    "    each_cen = YTArray(all_centers[idx], 'kpc')\n",
    "    each_rvir = YTQuantity(all_rvirs[idx] * 0.2, 'kpc')\n",
    "    '''\n",
    "    Simplified this to the basic yt load function, since you're not currently using any of the bespoke FOGGIE stuff\n",
    "    '''\n",
    "    ds = yt.load(all_available_snaps[idx])\n",
    "    \n",
    "    ads = ds.all_data()    \n",
    "    ds.add_particle_filter('stars')\n",
    "    ds.add_particle_filter('DM')\n",
    "            \n",
    "    # this uses yt to create spheres which contain the stars of each respective halo\n",
    "    halo_sphere = ds.sphere(center=each_cen,radius=each_rvir)\n",
    "    stars_ID = halo_sphere['stars', 'particle_index']\n",
    "    stars_loc = halo_sphere['stars','particle_position'].in_units('kpc')\n",
    "    corrected_stars_loc = stars_loc - each_cen # this places the halo center as the origin of its stars' coords\n",
    "    stars_mass = halo_sphere['stars','particle_mass'].in_units('Msun')\n",
    "    '''\n",
    "    len will give you number of stars; size gives you 3xN_stars since it's a position array\n",
    "    '''\n",
    "    print(each_rvir, len(corrected_stars_loc), str(halo_sphere)[10:16])\n",
    "    \n",
    "    if len(corrected_stars_loc) != 0:\n",
    "        radius_array = np.arange(YTQuantity(0.01, 'kpc'), each_rvir, bin_size)\n",
    "\n",
    "        title = \"star_timesteps/star_location_\" + str(starry_idx[0]) + '_' + \\\n",
    "                str(halo_sphere)[10:16] + '.txt'\n",
    "        with open(title, \"w\") as f:\n",
    "            for i in range(np.size(stars_mass)):\n",
    "                f.write(str(corrected_stars_loc[i].value[0]) + ' ' + str(corrected_stars_loc[i].value[1]) + ' ' \\\n",
    "                    + str(corrected_stars_loc[i].value[2]) + ' ' + str(stars_mass[i].value) + ' ' \\\n",
    "                    + str(each_rvir.value) + ' ' + str(each_cen.value[0]) + ' ' + str(each_cen.value[1]) \\\n",
    "                    + ' ' + str(each_cen.value[2]) + ' ' + str(stars_ID[i].value) + '\\n')\n",
    "        starry_steps.append(str(halo_sphere)[10:16])\n",
    "\n",
    "'''\n",
    "No need to carry the halo sphere objects around - all you're using is the timestep number; This probably accounts for\n",
    "some of the memory issues\n",
    "'''\n",
    "#         each_halo_radius_arrays.append(radius_array)    \n",
    "#         each_halo_spheres.append(halo_sphere)\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f17944",
   "metadata": {},
   "source": [
    "From the output earlier, it seems like there's something tragically wrong with DD1427 when it comes to data for halo 51. 98140389 is too large a number for stars within a halo sphere. Let's ignore DD1427 for now.\n",
    "\n",
    "UPDATE: Wed Jul 20, 10:09 PM: changed the limit from Rvir to 0.2 * Rvir and problem solved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e02c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now, we look for lost stars by finding the \"last time at which they appear\". \n",
    "# For many stars, the last time at which they appear is also the present (DD2427), meaning\n",
    "# they're not really lost, their measurement just stops there. If we wish to account\n",
    "# for this, we have to count backwards in time and set the first index to be\n",
    "# at the second most recent timestep, i.e. the one just before DD2427.\n",
    "\n",
    "i = len(starry_steps)-1 # This solves the index issue mentioned in the comment above.\n",
    "print (len(starry_steps),'steps contain stars')\n",
    "\n",
    "all_lost_stars = []\n",
    "all_categorized_lost_stars = []\n",
    "all_starry_timesteps = []\n",
    "mass_lost = np.zeros(len(starry_steps))\n",
    "\n",
    "while i >= 0: #29 because this corresponds to DD1427, the first timestep at which stars actually appear in halo 51\n",
    "    \n",
    "    lost_stars_by_timestep = []\n",
    "\n",
    "    timestep = starry_steps[i]\n",
    "    text_name = \"star_timesteps/star_location_\" + str(starry_idx[0]) + '_' + timestep + '.txt'\n",
    "    file = np.genfromtxt(text_name, dtype='str')\n",
    "\n",
    "    if file.ndim == 1:\n",
    "        star_loc_x = np.array([file[0]], dtype='float32')\n",
    "        star_loc_y = np.array([file[1]], dtype='float32')\n",
    "        star_loc_z = np.array([file[2]], dtype='float32')\n",
    "        star_mass = np.array([file[3]], dtype='float32')\n",
    "        rvir = np.array([file[4]], dtype='float32')\n",
    "        center_x = np.array([file[5]], dtype='float32')\n",
    "        center_y = np.array([file[6]], dtype='float32')\n",
    "        center_z = np.array([file[7]], dtype='float32')\n",
    "        star_ID = np.array([file[8]], dtype='float32')\n",
    "        \n",
    "    else:    \n",
    "        star_loc_x = np.array(file[:,0], dtype='float32')\n",
    "        star_loc_y = np.array(file[:,1], dtype='float32')\n",
    "        star_loc_z = np.array(file[:,2], dtype='float32')\n",
    "        star_mass = np.array(file[:,3], dtype='float32')\n",
    "        rvir = np.array(file[0,4], dtype='float32')\n",
    "        center_x = np.array(file[0,5], dtype='float32')\n",
    "        center_y = np.array(file[0,6], dtype='float32')\n",
    "        center_z = np.array(file[0,7], dtype='float32')\n",
    "        star_ID = np.array(file[:,8], dtype='float32')\n",
    "        \n",
    "    for star in star_ID:\n",
    "        if star not in all_lost_stars:\n",
    "            all_lost_stars.append(star)\n",
    "            lost_stars_by_timestep.append(star)\n",
    "            mass_lost[i] = np.sum(star_mass[star_ID == star])\n",
    "            \n",
    "            all_categorized_lost_stars.append(lost_stars_by_timestep)\n",
    "            all_starry_timesteps.append(timestep)\n",
    "            \n",
    "        print(np.size(lost_stars_by_timestep))\n",
    "            \n",
    "    i -= 1\n",
    "\n",
    "    \n",
    "#    print('finished ' + str(timestep) + ' with ' + str(np.size(lost_stars_by_timestep)) + ' stars')\n",
    "    \n",
    "all_lost_stars = np.array(all_lost_stars, dtype='object')\n",
    "all_categorized_lost_stars = np.array(all_categorized_lost_stars, dtype='object')\n",
    "all_starry_timesteps = np.array(all_starry_timesteps, dtype='object')\n",
    "\n",
    "print('Success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e0202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(all_categorized_lost_stars))\n",
    "print(np.shape(all_starry_timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77406512",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_categorized_lost_stars[131])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50dbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_times = np.zeros(len(starry_steps))\n",
    "\n",
    "i = 0\n",
    "for t in starry_steps:\n",
    "    timestep = int(str(t)[-4:])\n",
    "    relevant_times[i] = sim[timestep - 44].time_gyr\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f159b",
   "metadata": {},
   "source": [
    "Next, we look for the 5 greatest star mass losses and pinpoint the times at which these happen. The pinpointed times will then be compared to the tidal force plot to see if they match the peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc6699",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_losses = np.sort(mass_lost)[-3:]\n",
    "max_loss_times = np.zeros(np.size(max_losses))\n",
    "\n",
    "i = 0\n",
    "for max_mass_amount in max_losses:\n",
    "    max_loss_times[i] = relevant_times[mass_lost == max_mass_amount][0]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77d83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tidal_info = np.genfromtxt('saved_data/tidal_force_halo51.txt', dtype='str')\n",
    "tidal_times = np.array(tidal_info[:,0], dtype='float32')\n",
    "tidal_forces = np.array(tidal_info[:,1], dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4541699",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "plt.plot(relevant_times[:-1], mass_lost[:-1], color='black', label='M$_{lost}$')\n",
    "plt.plot(tidal_times, tidal_forces / (max(tidal_forces) / max(mass_lost[:-1])), color='blue')\n",
    "\n",
    "color_array = np.array(['red', 'magenta', 'orange'])\n",
    "\n",
    "for i in range(np.size(max_loss_times)):\n",
    "    plt.axvline(max_loss_times[i], color=color_array[i], linestyle='-.', \\\n",
    "                label=str(round(max_loss_times[i], 2)) + ' Gyr')\n",
    "\n",
    "plt.legend(loc='upper left', prop={'size': 12}, ncol=1)\n",
    "plt.title('star mass lost over time, compared\\nwith tidal force, halo 51', fontsize=19)\n",
    "plt.xlabel('time (Gyr)', fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.ylabel('F$_{tide}$ / ' + r'$\\frac{F_{tide,max}}{M_{lost,max}}$', fontsize=18)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.style.use('default')\n",
    "plt.savefig('plots/star_loss_51.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcea961",
   "metadata": {},
   "source": [
    "Now, it seems that the tidal force peaks don't match the greatest mass losses, and that there are still other mass losses that aren't close to any tidal force peaks at all (see: before 6 Gyr in the previous plot). But note that the tidal force here is only the one exerted by Tempest. What if the earlier mass losses might've arisen from the tidal forces exerted by other satellite halos? It's best to do another check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6302ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we load in the other halos in the TANGOS database.\n",
    "\n",
    "others = np.array([], dtype='object')\n",
    "for i in range(np.size(all_sats)):\n",
    "    if all_sats[i].halo_number not in starry_idx:\n",
    "        others = np.append(others, all_sats[i]) # this ensures we're only checking for the verified starry halos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we find the locations and virial mass values of all the satellite halos around halo 51.\n",
    "\n",
    "i = 0\n",
    "\n",
    "all_other_t = []\n",
    "all_other_r = []\n",
    "all_other_rvir = []\n",
    "all_other_mvir = []\n",
    "available_sat_51_mvir = []\n",
    "\n",
    "while i < np.size(others):\n",
    "    \n",
    "    # this finds the index of each of the OTHER halos (the ones around 51)\n",
    "    other_idx = others[i].halo_number\n",
    "    \n",
    "    # this uses pre-coded tangos stuff to get M_vir and distance measurements at all available redshifts\n",
    "    other_rvir, other_mvir, other_x, other_y, other_z, other_t = \\\n",
    "                        sim[-1][other_idx].calculate_for_progenitors('Rvir', 'Mvir', 'X', 'Y', 'Z', 't()')\n",
    "\n",
    "    # now, we have to correct for the distance of the other halos from 51, which itself is also moving. \n",
    "    # to do this, we need to subtract the position of the satellite by the center of halo 51.\n",
    "    \n",
    "    # because 51 and the other halos might not be observed at the exact same amount of redshifts,\n",
    "    # we first need to exclude the non-overlapping redshifts so that it's easier to subtract\n",
    "    sat_51_time = np.copy(all_sat_t)\n",
    "    sat_51_cen = np.copy(all_sat_cen)\n",
    "    sat_51_mvir = np.copy(all_sat_mvir)\n",
    "    sat_51_rvir = np.copy(all_sat_rvir)\n",
    "    \n",
    "    ### this checks for non-overlapping redshifts between 51 and others. \n",
    "    ### if non-overlapping, then array element set to 0\n",
    "    for j in range(np.size(other_t)):\n",
    "        if other_t[j] not in sat_51_time: \n",
    "            other_t[j] = 0.\n",
    "            other_x[j] = 0.\n",
    "            other_y[j] = 0.\n",
    "            other_z[j] = 0.\n",
    "            other_rvir[j] = 0.\n",
    "            other_mvir[j] = 0.\n",
    "            \n",
    "    ### this checks for non-overlapping redshifts between others and 51. \n",
    "    ### if non-overlapping, then array element set to 0\n",
    "    for k in range(np.size(sat_51_time)):\n",
    "        if sat_51_time[k] not in other_t:\n",
    "            sat_51_time[k] = 0.\n",
    "            sat_51_cen[k] = 0.\n",
    "            sat_51_mvir[k] = 0.\n",
    "            sat_51_rvir[k] = 0.\n",
    "\n",
    "    ### this removes all the zeros\n",
    "    other_x = other_x[other_t != 0.]\n",
    "    other_y = other_y[other_t != 0.]\n",
    "    other_z = other_z[other_t != 0.]\n",
    "    other_rvir = other_rvir[other_t != 0.]\n",
    "    other_mvir = other_mvir[other_t != 0.]\n",
    "    other_t = other_t[other_t != 0.]\n",
    "    \n",
    "    sat_51_cen = sat_51_cen[sat_51_time != 0.]\n",
    "    sat_51_mvir = sat_51_mvir[sat_51_time != 0.]\n",
    "    sat_51_rvir = sat_51_rvir[sat_51_time != 0.]\n",
    "    sat_51_time = sat_51_time[sat_51_time != 0.]\n",
    "        \n",
    "    ### now we correct the x, y and z coordinates by the center of 51 at each snapshot\n",
    "    for snapshot in range(np.size(other_t)):\n",
    "        other_x[snapshot] -= sat_51_cen[snapshot][0]\n",
    "        other_y[snapshot] -= sat_51_cen[snapshot][1]\n",
    "        other_z[snapshot] -= sat_51_cen[snapshot][2]\n",
    "        \n",
    "    # finally, we get the 3D distance and scale it by the virial radius of the host halo (Tempest)\n",
    "    other_r = np.sqrt(other_x**2 + other_y**2 + other_z**2)\n",
    "\n",
    "    all_other_t.append(other_t)\n",
    "    all_other_r.append(other_r * 1000)\n",
    "    all_other_rvir.append(other_rvir)\n",
    "    all_other_mvir.append(other_mvir)\n",
    "    available_sat_51_mvir.append(sat_51_mvir)\n",
    "        \n",
    "    print(other_idx)\n",
    "            \n",
    "    i += 1\n",
    "    \n",
    "all_other_t = np.array(all_other_t, dtype='object')\n",
    "all_other_r = np.array(all_other_r, dtype='object')\n",
    "all_other_rvir = np.array(all_other_rvir, dtype='object')\n",
    "all_other_mvir = np.array(all_other_mvir, dtype='object')\n",
    "available_sat_51_mvir = np.array(available_sat_51_mvir, dtype='object')\n",
    "\n",
    "print('success!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = 4.30091e-3 # unit: pc (km/s)^2 / Msun\n",
    "\n",
    "all_sat_Ftide = []\n",
    "\n",
    "for i in range(np.size(all_other_t)):\n",
    "    M = available_sat_51_mvir[i] # unit: Msun\n",
    "    m = all_other_mvir[i] #        unit: Msun\n",
    "    rvir = all_other_rvir[i] * 1000 # converting kpc to pc\n",
    "    d = all_other_r[i] * 1000 # converting kpc to pc\n",
    "    F = 2*G*M*m*rvir / (d**3)\n",
    "    all_sat_Ftide.append(F)\n",
    "        \n",
    "all_sat_Ftide = np.array(all_sat_Ftide, dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a233cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, let's plot the tidal force of each halo on 51!\n",
    "\n",
    "fig, a1 = plt.subplots(figsize=(8,8))\n",
    "\n",
    "for i in range(np.size(all_other_t)):\n",
    "    a1.plot(all_other_t[i], all_sat_Ftide[i], label='tidal, ' + str(others[i].halo_number))\n",
    "\n",
    "a1.plot(tidal_times, tidal_forces, label='tidal, Tempest')\n",
    "\n",
    "a2 = a1.twinx()\n",
    "a2.plot(relevant_times[:-1], mass_lost[:-1], color='black', label=\"mass loss, 51\")\n",
    "\n",
    "a1.legend(loc='upper left', prop={'size': 9}, ncol=2)\n",
    "a2.legend(loc='upper right', prop={'size': 9}, ncol=3)\n",
    "\n",
    "plt.title('tidal force on halo 51 from other halos vs. time', fontsize=19)\n",
    "plt.xlabel('time (Gyr)', fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "a1.set_ylabel('F$_{tide}$', fontsize=18)\n",
    "a1.set_yscale('log')\n",
    "a1.tick_params(axis='y', labelsize=12)\n",
    "a2.set_ylabel('M$_{*,lost}$ (M$_\\odot$)', fontsize=18)\n",
    "a2.set_yscale('log')\n",
    "a2.tick_params(axis='y', labelsize=12)\n",
    "plt.tight_layout()\n",
    "plt.style.use('default')\n",
    "plt.savefig('plots/tidal_and_star_loss_51.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe2439",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# How to read in file that contains data on every star that is in Tempest's stellar halo at z=0\n",
    "f = h5py.File('/Users/bnguyen/Downloads/Tempest_RD0042_allhalostardata.h5','r')\n",
    "pids = f['particle_IDs'][:] # particle index of star - constant across simulation (int)\n",
    "ptind = f['timestep_location'][:] # index of timestep at which star formed (int; 0->DD0044)\n",
    "hids = f['host_IDs'].asstr()[:] # unique ID of halo in which star forms (string, constant across simulation)\n",
    "pp = f['particle_positions'][:] # location at which star forms ([x,y,z], float, Mpc)\n",
    "ct = f['particle_creation_times'][:] # time at which star was formed (float, Gyr)\n",
    "ph = f['particle_hosts'][:] # halo number of halo in which star forms (int, holds only for timestep)\n",
    "f.close()\n",
    "# Note: some star particles form before our first saved timestep or in halos that our halo finder has lost track of.\n",
    "# The vast majority can still be reliably assigned to a halo via other methods and therefore have a 'host_IDs' value.\n",
    "# However, they may have 0s or -1s for 'timestep_location' and/or 'particle_hosts'.\n",
    "# The 'host_IDs' value is the most important means of grouping halo stars. Star particles that formed in the same halo\n",
    "# at different timesteps will have different 'timestep_locations' values and possibly different 'particle_hosts' values,\n",
    "# but they will have the same 'host_IDs' value. The 'host_IDs' value can be understood as follows:\n",
    "#   The number before the underscore is the timestep at which the star-forming halo was last distinguished by the halo\n",
    "#   finder as an independent halo, either before it merged with another, more massive halo or before it lost too many\n",
    "#   particles to be tracked.\n",
    "#   The number after the underscore is the halo number of the halo at this timestep.\n",
    "#   So, for example, a 'host_IDs' value of '1878_101' means that this star formed in a halo that is last \n",
    "#   distinguished at timestep DD1878 and has halo_number = 101 at this timestep. A star with 'host_IDs'='2427_1'\n",
    "#   formed inside of Tempest itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608fa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_stars = np.unique(all_lost_stars)\n",
    "\n",
    "creation_times = np.array([], dtype='object')\n",
    "corresponding_halo = np.array([], dtype='object')\n",
    "\n",
    "for star in lost_stars:\n",
    "    if star in pids:\n",
    "        creation_times = np.append(creation_times, ct[pids == star][0])\n",
    "        corresponding_halo = np.append(corresponding_halo, hids[pids == star][0])\n",
    "        print(ct[pids == star][0], hids[pids == star][0])\n",
    "        \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fca97e",
   "metadata": {},
   "source": [
    "Next, we identify the \"early stars\", i.e. stars that formed before a point in time where most of the stars formed later are categorized as part of 2427_51. From the previous cell, we can see that this point in time is 7.7366742133831545 Gyr. Thus, we'll set the \"threshold\" for early stars to be at 7.7366742133831545 Gyr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d6f33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 7.7366742133831545\n",
    "\n",
    "early_star_times = creation_times[creation_times < threshold]\n",
    "early_star_halo_origins = corresponding_halo[creation_times < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9c1fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "plt.hist(early_star_halo_origins, bins=np.size(np.unique(early_star_halo_origins)))\n",
    "ax.tick_params('x', rotation=60)\n",
    "\n",
    "plt.title('histogram of origins of early stars in halo 51', fontsize=19)\n",
    "plt.xlabel('halo of birth', fontsize=18)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.ylabel('number of compatriots', fontsize=18)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.style.use('default')\n",
    "plt.savefig('plots/halo51_early_star_origins.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_categorized_lost_stars[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3151fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lost = all_categorized_lost_stars[all_starry_timesteps != 'DD2427']\n",
    "all_lost_times = all_starry_timesteps[all_starry_timesteps != 'DD2427']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97957a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "times_in_gyr = np.zeros(np.size(all_lost_times))\n",
    "\n",
    "j = 0\n",
    "while j < np.size(times_in_gyr):\n",
    "    times_in_gyr[j] = sim[int(str(all_lost_times[j][2:])) - 44].time_gyr\n",
    "    j += 1\n",
    "    \n",
    "print(times_in_gyr)\n",
    "print(np.size(times_in_gyr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c12e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "lost_creation_times = []\n",
    "\n",
    "for lost_array in all_lost:\n",
    "    star_creation_times = []\n",
    "    for lost_star in lost_array:\n",
    "        if lost_star in pids:\n",
    "            star_creation_times.append(ct[pids == lost_star][0])\n",
    "    print(np.size(star_creation_times))\n",
    "    lost_creation_times.append(star_creation_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d0dcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.size(lost_creation_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59f7f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
